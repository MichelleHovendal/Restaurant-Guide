{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Explainer Notebook\n",
    "\n",
    "This notebook is done as part of the final project for 02806 Social Data Analysis and Visualization, Technical University of Denmark.\n",
    "\n",
    "This notebook contains all the code used for the website: https://restaurant-guide.github.io/\n",
    "\n",
    "Please note that this notebook is only rendered with data from 2019-2021, so not the full dataset. This is done, because of GitHub storage limitations. \n",
    "\n",
    "## 1. Motivation\n",
    "### 1.1 Purpose \n",
    "\n",
    "The aim of the final project for Social Data Analysis and Visualization is to investigate restaurants and their reviews through a dataset from Yelp. The company Yelp will be described in the next subsection. Nowadays before going to a restaurant, you look it up on Google. Here it is possible to check the ratings of a restaurant and the comments. Hence, fake reviews are a hot topic, where business owners can promote their business falsely. The idea of this project is to find the best restaurant based on chosen types of restaurant, kitchen, price, review score without fake reviews in the dataset. From this, the user is able to find the perfect restaurant through an interactive application, but also see how the fake reviews are detected.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<!-- The aim of the project is to find the best restaurant based on chosen type of restaurant, kitchen, price, review score without fake reviews.  -->\n",
    "\n",
    "\n",
    "### 1.2 Data\n",
    "The dataset considered for this project is from Yelp, which is an American company founded in 2004. The idea behind the company is to publish crow-sourced reviews about businesses through their website Yelp.com and mobile app Yelp. In the second quarter of 2019, Yelp has an average of 61.8 million unique visitors through their website, while it was 76.7 million unique visitors in the app. As the internet gets filled with more and more information and the likelihood of the information being false, Yelp can then provides a local platform for people to discover true information. So the dataset from Yelp considers different businesses and not only restaurants, which is the focus of this project. If a restaurant is not part of Yelp, they are not considered in this project. \n",
    "\n",
    "Overall, the Yelp dataset is a subset of Yelp's businesses, reviews and users, which covers 11 metropolitan areas. All the dataset consists of the following information:\n",
    "* 8,635,403 reviews\n",
    "* 160,585 business\n",
    "* 200,000 pictures\n",
    "* 2,189,457 unique users\n",
    "\n",
    "The dataset stretches over a period from 14th of October 2004 to 28th of January 2021. \n",
    "\n",
    "For this project, three of Yelps dataset is used. The main dataset consists of all the different businesses and some attributes explaining opening hours, price range and category. Furthermore, a dataset consisting of all the reviews and when the reviews are given is also used. To detect anomalies in the data, the dataset about the user that has given a review is also used. So to sum up, the following data files were used throughout this project\n",
    "* yelp_academic_dataset_business.json (121.466 KB)\n",
    "* yelp_academic_dataset_review.json (6.774.100 KB)\n",
    "* yelp_academic_dataset_user.json (3.598.150 KB)\n",
    "\n",
    "See reference [1] for the data. \n",
    "\n",
    "## 2. Basic stats. Let's understand the dataset better\n",
    "\n",
    "Before doing data analysis on the dataset, it is key to do some basic statistics on the chosen dataset. Before doing basic statistics, some data cleaning and preprocessing are done.\n",
    "\n",
    "### 2.1 Data cleaning & preprocessing\n",
    "\n",
    "As mentioned in the section about the dataset, there are multiple businesses considered in our dataset. The businesses that do not have the word *Restaurant* in the column `categories` will not be considered. Further, restaurants that are closed have been removed, because it does not make sense to give advice for the user to go to a closed restaurant. \n",
    "To get some useful information from the `categories` column, two new variables are created. The first variable explains the kitchen type of the restaurant, whereas the second variable explains the type of restaurant, i.e. if it is a pizzeria. The list of words for the two variables are presented below\n",
    "\n",
    "* Kitchen type: Thai, Chinese, Japanese, Korean, Indian, American, Caribean, Italian, Mediterranean, Mexican, Cajun, Vietnamese and Greek.\n",
    "* Type: Food, nightlife, bars, sandwiches, pizza, breakfast & brunch, fast food, burgers, salad, buffet, cafes, coffee & tea, vegetarian, steakhouse, sushi bars, diners and wine bars. \n",
    "\n",
    "The data from Yelp also give what state the different restaurants are in but in abbrivations. Hence the full state name and to do some plotting later on where the states are, the states latitude and longitude are also inserted. \n",
    "\n",
    "From merging the three datasets, the shape is `(6.588.460, 27)`, to make with more compatible a shorter time period is considered, namely 1st of January 2014 to 28th of January 2021, which gives a shape of `(5.177.322, 27)`. Remeber that these numbers cannot be compared with the shapes below, since this notebook only covers around two years.\n",
    "\n",
    "See to the full dataprep, please see the python file: `NAME OF FILE`\n",
    "\n",
    "#### Libaries\n",
    "The libraries used for this project are presented below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1003\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1003\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error(url) {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < css_urls.length; i++) {\n",
       "      const url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.3.1.min.js\": \"YF85VygJKMVnHE+lLv2AM93Vbstr0yo2TbIu5v8se5Rq3UQAUmcuh4aaJwNlpKwa\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.3.1.min.js\": \"KKuas3gevv3PvrlkyCMzffFeaMq5we/a2QsP5AUoS3mJ0jmaCL7jirFJN3GoE/lM\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.3.1.min.js\": \"MK/uFc3YT18pkvvXRl66tTHjP0/dxoSH2e/eiNMFIguKlun2+WVqaPTWmUy/zvh4\"};\n",
       "\n",
       "    for (let i = 0; i < js_urls.length; i++) {\n",
       "      const url = js_urls[i];\n",
       "      const element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      if (url in hashes) {\n",
       "        element.crossOrigin = \"anonymous\";\n",
       "        element.integrity = \"sha384-\" + hashes[url];\n",
       "      }\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  \n",
       "  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.3.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.3.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.3.1.min.js\"];\n",
       "  var css_urls = [];\n",
       "  \n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "    \n",
       "    \n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      \n",
       "    for (var i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "    if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1003\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1003\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.3.1.min.js\": \"YF85VygJKMVnHE+lLv2AM93Vbstr0yo2TbIu5v8se5Rq3UQAUmcuh4aaJwNlpKwa\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.3.1.min.js\": \"KKuas3gevv3PvrlkyCMzffFeaMq5we/a2QsP5AUoS3mJ0jmaCL7jirFJN3GoE/lM\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.3.1.min.js\": \"MK/uFc3YT18pkvvXRl66tTHjP0/dxoSH2e/eiNMFIguKlun2+WVqaPTWmUy/zvh4\"};\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      if (url in hashes) {\n        element.crossOrigin = \"anonymous\";\n        element.integrity = \"sha384-\" + hashes[url];\n      }\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.3.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.3.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.3.1.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1003\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.0.1-cp37-cp37m-win_amd64.whl (23.9 MB)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\miche\\anaconda3\\lib\\site-packages (from gensim) (1.6.2)\n",
      "Collecting smart-open>=1.8.1\n",
      "  Downloading smart_open-5.0.0-py3-none-any.whl (56 kB)\n",
      "Collecting Cython==0.29.21\n",
      "  Downloading Cython-0.29.21-cp37-cp37m-win_amd64.whl (1.6 MB)\n",
      "Requirement already satisfied: numpy>=1.11.3 in c:\\users\\miche\\anaconda3\\lib\\site-packages (from gensim) (1.19.5)\n",
      "Installing collected packages: smart-open, Cython, gensim\n",
      "  Attempting uninstall: Cython\n",
      "    Found existing installation: Cython 0.29.23\n",
      "    Uninstalling Cython-0.29.23:\n",
      "      Successfully uninstalled Cython-0.29.23\n",
      "Successfully installed Cython-0.29.21 gensim-4.0.1 smart-open-5.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Miche\\anaconda3\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# plot functions\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.io import show, output_notebook, curdoc, output_file\n",
    "from bokeh.models import ColumnDataSource, FactorRange, Legend, HoverTool, GeoJSONDataSource, \\\n",
    "                        LinearColorMapper, ColorBar, NumeralTickFormatter, Div, Select, TableColumn, \\\n",
    "                        DataTable, CheckboxGroup, Tabs, Panel, CheckboxButtonGroup, RadioButtonGroup\n",
    "from bokeh.application.handlers import FunctionHandler\n",
    "from bokeh.application import Application\n",
    "from bokeh.palettes import Category20c, Pastel1, Set3, Blues\n",
    "from bokeh.layouts import column, row, WidgetBox, gridplot\n",
    "from bokeh.embed import file_html\n",
    "from bokeh.resources import CDN\n",
    "from bokeh.tile_providers import get_provider, Vendors\n",
    "from bokeh.transform import linear_cmap,factor_cmap\n",
    "output_notebook()\n",
    "\n",
    "#Anomaly detection\n",
    "\n",
    "import sys\n",
    "!{sys.executable} -m pip install gensim\n",
    "!{sys.executable} -m pip install python-Levenshtein\n",
    "\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.porter import PorterStemmer\n",
    "from collections import Counter\n",
    "from sklearn.ensemble import IsolationForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/Miche/OneDrive - Danmarks Tekniske Universitet/MMC/2. Semester/Social Data/websites/Restaurant-Guide/data'\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['business_id', 'name', 'address', 'city', 'state', 'postal_code',\n",
      "       'latitude', 'longitude', 'stars', 'review_count', 'attributes',\n",
      "       'categories', 'hours', 'cat_kitchen', 'cat_type', 'state_name',\n",
      "       'latitude_state', 'longitude_state', 'PriceRange', 'AvgPrice',\n",
      "       'user_id', 'review_stars', 'text', 'date', 'username', 'user_count',\n",
      "       'average_stars'],\n",
      "      dtype='object')\n",
      "shape of dataset (1427833, 27)\n"
     ]
    }
   ],
   "source": [
    "df_2019 = pd.read_csv('yelp_reviews_RV_categories_2019.csv')\n",
    "df_2020 = pd.read_csv('yelp_reviews_RV_categories_2020.csv')\n",
    "\n",
    "df = df_2019.append([df_2020]) #appending the two datasets\n",
    "\n",
    "print(df.columns) #checking our columns\n",
    "print('shape of dataset', df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timeperiod of the dataset\n",
      "2019-01-01 00:00:09\n",
      "2021-01-28 15:23:52\n"
     ]
    }
   ],
   "source": [
    "print('Timeperiod of the dataset')\n",
    "print (df.date.min())\n",
    "print (df.date.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>stars</th>\n",
       "      <th>review_count</th>\n",
       "      <th>...</th>\n",
       "      <th>longitude_state</th>\n",
       "      <th>PriceRange</th>\n",
       "      <th>AvgPrice</th>\n",
       "      <th>user_id</th>\n",
       "      <th>review_stars</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>username</th>\n",
       "      <th>user_count</th>\n",
       "      <th>average_stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7bioKzHBPPRdM7-jJQAwkg</td>\n",
       "      <td>Cafe Aion</td>\n",
       "      <td>1235 Pennsylvania Ave</td>\n",
       "      <td>Boulder</td>\n",
       "      <td>CO</td>\n",
       "      <td>80302</td>\n",
       "      <td>40.008789</td>\n",
       "      <td>-105.276503</td>\n",
       "      <td>3.5</td>\n",
       "      <td>144</td>\n",
       "      <td>...</td>\n",
       "      <td>-105.358887</td>\n",
       "      <td>$$</td>\n",
       "      <td>20</td>\n",
       "      <td>eXRC79iX60xwA1UuGRuWNg</td>\n",
       "      <td>4</td>\n",
       "      <td>Best paella I have enjoyed in a long time on a...</td>\n",
       "      <td>2019-09-16 19:26:44</td>\n",
       "      <td>Daniel</td>\n",
       "      <td>376</td>\n",
       "      <td>4.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7bioKzHBPPRdM7-jJQAwkg</td>\n",
       "      <td>Cafe Aion</td>\n",
       "      <td>1235 Pennsylvania Ave</td>\n",
       "      <td>Boulder</td>\n",
       "      <td>CO</td>\n",
       "      <td>80302</td>\n",
       "      <td>40.008789</td>\n",
       "      <td>-105.276503</td>\n",
       "      <td>3.5</td>\n",
       "      <td>144</td>\n",
       "      <td>...</td>\n",
       "      <td>-105.358887</td>\n",
       "      <td>$$</td>\n",
       "      <td>20</td>\n",
       "      <td>eXRC79iX60xwA1UuGRuWNg</td>\n",
       "      <td>4</td>\n",
       "      <td>Best paella I have enjoyed in a long time on a...</td>\n",
       "      <td>2019-09-16 19:26:44</td>\n",
       "      <td>Daniel</td>\n",
       "      <td>376</td>\n",
       "      <td>4.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7bioKzHBPPRdM7-jJQAwkg</td>\n",
       "      <td>Cafe Aion</td>\n",
       "      <td>1235 Pennsylvania Ave</td>\n",
       "      <td>Boulder</td>\n",
       "      <td>CO</td>\n",
       "      <td>80302</td>\n",
       "      <td>40.008789</td>\n",
       "      <td>-105.276503</td>\n",
       "      <td>3.5</td>\n",
       "      <td>144</td>\n",
       "      <td>...</td>\n",
       "      <td>-105.358887</td>\n",
       "      <td>$$</td>\n",
       "      <td>20</td>\n",
       "      <td>eXRC79iX60xwA1UuGRuWNg</td>\n",
       "      <td>4</td>\n",
       "      <td>Best paella I have enjoyed in a long time on a...</td>\n",
       "      <td>2019-09-16 19:26:44</td>\n",
       "      <td>Daniel</td>\n",
       "      <td>376</td>\n",
       "      <td>4.29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id       name                address     city state  \\\n",
       "0  7bioKzHBPPRdM7-jJQAwkg  Cafe Aion  1235 Pennsylvania Ave  Boulder    CO   \n",
       "1  7bioKzHBPPRdM7-jJQAwkg  Cafe Aion  1235 Pennsylvania Ave  Boulder    CO   \n",
       "2  7bioKzHBPPRdM7-jJQAwkg  Cafe Aion  1235 Pennsylvania Ave  Boulder    CO   \n",
       "\n",
       "  postal_code   latitude   longitude  stars  review_count  ...  \\\n",
       "0       80302  40.008789 -105.276503    3.5           144  ...   \n",
       "1       80302  40.008789 -105.276503    3.5           144  ...   \n",
       "2       80302  40.008789 -105.276503    3.5           144  ...   \n",
       "\n",
       "  longitude_state PriceRange AvgPrice                 user_id review_stars  \\\n",
       "0     -105.358887         $$       20  eXRC79iX60xwA1UuGRuWNg            4   \n",
       "1     -105.358887         $$       20  eXRC79iX60xwA1UuGRuWNg            4   \n",
       "2     -105.358887         $$       20  eXRC79iX60xwA1UuGRuWNg            4   \n",
       "\n",
       "                                                text                 date  \\\n",
       "0  Best paella I have enjoyed in a long time on a...  2019-09-16 19:26:44   \n",
       "1  Best paella I have enjoyed in a long time on a...  2019-09-16 19:26:44   \n",
       "2  Best paella I have enjoyed in a long time on a...  2019-09-16 19:26:44   \n",
       "\n",
       "   username user_count  average_stars  \n",
       "0    Daniel        376           4.29  \n",
       "1    Daniel        376           4.29  \n",
       "2    Daniel        376           4.29  \n",
       "\n",
       "[3 rows x 27 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by checking NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any missing values: 13558\n"
     ]
    }
   ],
   "source": [
    "print('Any missing values:', df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From further analysis, the missing values were in the columns: `hours`,`address` and `username`. Since these are not being used, these can be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any missing values: 0\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(['hours','address', 'username'],axis=1) \n",
    "print('Any missing values:', df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the top categories in different columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 304. MiB for an array with shape (13, 3060959) and data type object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-8a9dc39eb304>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#exploding the dataframe so the categories column is not a list type\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdf_duplicates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdf_explode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_duplicates\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcategories\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_duplicates\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'categories'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m', '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexplode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'categories'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Top categories in the dataset'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mexplode\u001b[1;34m(self, column, ignore_index)\u001b[0m\n\u001b[0;32m   7282\u001b[0m         \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7283\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexplode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 7284\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   7285\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7286\u001b[0m             \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mibase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefault_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mjoin\u001b[1;34m(self, other, on, how, lsuffix, rsuffix, sort)\u001b[0m\n\u001b[0;32m   8109\u001b[0m         \"\"\"\n\u001b[0;32m   8110\u001b[0m         return self._join_compat(\n\u001b[1;32m-> 8111\u001b[1;33m             \u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlsuffix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlsuffix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrsuffix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrsuffix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   8112\u001b[0m         )\n\u001b[0;32m   8113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_join_compat\u001b[1;34m(self, other, on, how, lsuffix, rsuffix, sort)\u001b[0m\n\u001b[0;32m   8141\u001b[0m                 \u001b[0mright_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8142\u001b[0m                 \u001b[0msuffixes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlsuffix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrsuffix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 8143\u001b[1;33m                 \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   8144\u001b[0m             )\n\u001b[0;32m   8145\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[0mvalidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m     )\n\u001b[1;32m---> 89\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36mget_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    695\u001b[0m             \u001b[0maxes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mllabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjoin_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    696\u001b[0m             \u001b[0mconcat_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 697\u001b[1;33m             \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    698\u001b[0m         )\n\u001b[0;32m    699\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\concat.py\u001b[0m in \u001b[0;36mconcatenate_block_managers\u001b[1;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m             b = make_block(\n\u001b[1;32m---> 83\u001b[1;33m                 \u001b[0m_concatenate_join_units\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjoin_units\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconcat_axis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m                 \u001b[0mplacement\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplacement\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m                 \u001b[0mndim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\concat.py\u001b[0m in \u001b[0;36m_concatenate_join_units\u001b[1;34m(join_units, concat_axis, copy)\u001b[0m\n\u001b[0;32m    313\u001b[0m     to_concat = [\n\u001b[0;32m    314\u001b[0m         \u001b[0mju\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_reindexed_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mempty_dtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mempty_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupcasted_na\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mupcasted_na\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 315\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mju\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mjoin_units\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    316\u001b[0m     ]\n\u001b[0;32m    317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\concat.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    313\u001b[0m     to_concat = [\n\u001b[0;32m    314\u001b[0m         \u001b[0mju\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_reindexed_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mempty_dtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mempty_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupcasted_na\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mupcasted_na\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 315\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mju\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mjoin_units\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    316\u001b[0m     ]\n\u001b[0;32m    317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\concat.py\u001b[0m in \u001b[0;36mget_reindexed_values\u001b[1;34m(self, empty_dtype, upcasted_na)\u001b[0m\n\u001b[0;32m    296\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindexers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 298\u001b[1;33m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malgos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake_nd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    299\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    300\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\algorithms.py\u001b[0m in \u001b[0;36mtake_nd\u001b[1;34m(arr, indexer, axis, out, fill_value, allow_fill)\u001b[0m\n\u001b[0;32m   1752\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"F\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1753\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1754\u001b[1;33m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1755\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1756\u001b[0m     func = _get_take_nd_function(\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 304. MiB for an array with shape (13, 3060959) and data type object"
     ]
    }
   ],
   "source": [
    "#exploding the dataframe so the categories column is not a list type\n",
    "df_duplicates = df.drop_duplicates(subset=['name','date'])\n",
    "df_explode = df_duplicates.assign(categories = df_duplicates['categories'].str.split(', ')).explode('categories')\n",
    "\n",
    "print('Top categories in the dataset')\n",
    "print(df_explode['categories'].value_counts().head(10))\n",
    "print('Checking that all rows have the value *Restaurant*:', df_duplicates.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making sure that all rows have restaurants in their cateogy, which is true. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Top categories in the dataset based on our own variables')\n",
    "print(df['cat_kitchen'].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Top categories in the dataset based on our own variables')\n",
    "print(df['cat_type'].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Count of the different price ranges')\n",
    "print(df['PriceRange'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some descriptive statisics for the different variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['name','city','state','cat_kitchen','cat_type','PriceRange']\n",
    "df[variables].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there are 11 unique states in the dataset and 302 unique cities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['stars', 'AvgPrice']\n",
    "round(df[variables].describe(),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 5))\n",
    "sns.boxplot(df['stars'], color='#2b8cbe', saturation=0.5)\n",
    "plt.tight_layout(h_pad=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,5))\n",
    "selected = ['stars']\n",
    "plt.title('Stars')\n",
    "sns.boxplot(x='state_name', y='stars', data=df, palette='YlGnBu', saturation=0.5)\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout(h_pad=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAYBE SOME MORE DESCRIPTIVE PLOTS?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis\n",
    "\n",
    "### 3.1. General Overview of the data\n",
    "\n",
    "Starting out by illustrating the different states and how many restaurants there are in each state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurants = df.drop_duplicates(subset=['name','state'])\n",
    "restaurant_ = restaurants.groupby(['state_name', 'latitude_state', 'longitude_state']).size().reset_index(name='Counts').sort_values(by='Counts',ascending=False)\n",
    "restaurants.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below it used to define the sizes of the circle on our world map. The function is forcing the count values to be between 15 and 50. This is done, because in some states there are above 1000 of restaurants, hence why the circle will fill the whole plot without seeing the map. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_max = max(restaurant_['Counts'])\n",
    "r_min = min(restaurant_['Counts'])\n",
    "t_min = 15\n",
    "t_max = 50\n",
    "\n",
    "restaurant_['Size'] = (restaurant_['Counts'] - r_min)/(r_max - r_min) * (t_max - t_min) + t_min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map over the different states, where we have restaurants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to switch from lat/long to mercator coordinates\n",
    "def x_coord(x, y):\n",
    "    \n",
    "    lat = x\n",
    "    lon = y\n",
    "    \n",
    "    r_major = 6378137.000\n",
    "    x = r_major * np.radians(lon)\n",
    "    scale = x/lon\n",
    "    y = 180.0/np.pi * np.log(np.tan(np.pi/4.0 + \n",
    "        lat * (np.pi/180.0)/2.0)) * scale\n",
    "    return (x, y)\n",
    "# Define coord as tuple (lat,long)\n",
    "restaurants_copy = restaurant_.copy()\n",
    "restaurants_copy['coordinates'] = list(zip(restaurants_copy['latitude_state'], restaurants_copy['longitude_state']))\n",
    "# Obtain list of mercator coordinates\n",
    "mercators = [x_coord(x, y) for x, y in restaurants_copy['coordinates']]\n",
    "\n",
    "# Create mercator column in our df\n",
    "restaurants_copy['mercator'] = mercators\n",
    "# Split that column out into two separate columns - mercator_x and mercator_y\n",
    "restaurants_copy[['mercator_x', 'mercator_y']] = restaurants_copy['mercator'].apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select tile set to use\n",
    "chosentile = get_provider(Vendors.CARTODBPOSITRON)\n",
    "\n",
    "tooltips = [(\"State\",\"@state_name\"), (\"Count\", \"@Counts\")]\n",
    "\n",
    "counts = restaurants_copy['Counts'].to_list()\n",
    "\n",
    "p = figure(title = 'Number of restaurants in North American', \n",
    "           x_axis_type=\"mercator\", y_axis_type=\"mercator\", \n",
    "           x_axis_label = 'Longitude', y_axis_label = 'Latitude', \n",
    "           tooltips = tooltips, plot_width=800, plot_height=600)\n",
    "\n",
    "p.add_tile(chosentile)\n",
    "\n",
    "p.circle(x = 'mercator_x', y = 'mercator_y', color = 'lightblue', source=restaurants_copy, \n",
    "         size='Size', fill_alpha = 0.7)\n",
    "show(p)\n",
    "html = file_html(p, CDN, \"North America - Map\")\n",
    "# print(html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General bar charts over the three main variables, state, kitchen and type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_state_ = restaurants.groupby(['cat_kitchen']).size().reset_index(name='Counts')\n",
    "group_state_['Type'] = group_state_['cat_kitchen'].astype(str)\n",
    "df_dict_ = group_state_.to_dict('list')\n",
    "\n",
    "group_state__ = restaurants.groupby(['cat_type']).size().reset_index(name='Counts')\n",
    "group_state__['Type'] = group_state__['cat_type'].astype(str)\n",
    "df_dict__ = group_state__.to_dict('list')\n",
    "\n",
    "group_state = restaurants.groupby(['state_name']).size().reset_index(name='Counts')\n",
    "group_state['state'] = group_state['state_name'].astype(str)\n",
    "df_dict = group_state.to_dict('list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Count of restaurants by State'\n",
    "xlabel = 'State'\n",
    "range_x = group_state.state.unique().tolist()\n",
    "\n",
    "plot1 = figure(x_range=FactorRange(factors=range_x), y_range=(0,2500), plot_width=800, plot_height=500,\n",
    "               x_axis_label=xlabel, toolbar_location=None, title=title)\n",
    "plot1.vbar(x='state_name', width=0.7, bottom=0,\n",
    "           top='Counts', source=df_dict, color='lightblue')\n",
    "\n",
    "# hover tool\n",
    "plot1.add_tools(HoverTool(tooltips=[('Count', \"@Counts{1}\")]))\n",
    "\n",
    "# axis ticks\n",
    "plot1.xaxis.major_tick_line_color = None \n",
    "plot1.xaxis.minor_tick_line_color = None \n",
    "plot1.yaxis.major_tick_line_color = None  \n",
    "plot1.yaxis.minor_tick_line_color = None  \n",
    "plot1.title.text_font_size = '13pt'\n",
    "plot1.title.align = 'center'\n",
    "\n",
    "# show(plot1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Count of restaurants by Kitchen'\n",
    "range_x = group_state_['cat_kitchen'].unique().tolist()\n",
    "xlabel = 'Kitchen type'\n",
    "\n",
    "plot2 = figure(x_range=FactorRange(factors=range_x),y_range=(0,2500),  plot_width=800, plot_height=500,\n",
    "               x_axis_label=xlabel, toolbar_location=None, title=title)\n",
    "plot2.vbar(x='Type', width=0.7, bottom=0,\n",
    "           top='Counts', source=df_dict_, color='lightblue')\n",
    "\n",
    "# hover tool\n",
    "plot2.add_tools(HoverTool(tooltips=[('Count', \"@Counts\")]))\n",
    "\n",
    "# axis ticks\n",
    "plot2.xaxis.major_tick_line_color = None \n",
    "plot2.xaxis.minor_tick_line_color = None \n",
    "plot2.yaxis.major_tick_line_color = None  \n",
    "plot2.yaxis.minor_tick_line_color = None  \n",
    "plot2.xaxis.major_label_orientation = \"vertical\"\n",
    "plot2.title.text_font_size = '13pt'\n",
    "plot2.title.align = 'center'\n",
    "\n",
    "# show(plot2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Count of restaurants by Type'\n",
    "range_x = group_state__['cat_type'].unique().tolist()\n",
    "xlabel = 'Types'\n",
    "\n",
    "plot3 = figure(x_range=FactorRange(factors=range_x), y_range=(0,2500), plot_width=600, plot_height=500,\n",
    "               x_axis_label=xlabel, toolbar_location=None, title=title)\n",
    "plot3.vbar(x='Type', width=0.7, bottom=0,\n",
    "           top='Counts', source=df_dict__, color='lightblue')\n",
    "\n",
    "# hover tool\n",
    "plot3.add_tools(HoverTool(tooltips=[('Count', \"@Counts\")]))\n",
    "\n",
    "# axis ticks\n",
    "plot3.xaxis.major_tick_line_color = None \n",
    "plot3.xaxis.minor_tick_line_color = None \n",
    "plot3.yaxis.major_tick_line_color = None  \n",
    "plot3.yaxis.minor_tick_line_color = None  \n",
    "plot3.xaxis.major_label_orientation = \"vertical\"\n",
    "plot3.title.text_font_size = '13pt'\n",
    "plot3.title.align = 'center'\n",
    "\n",
    "# show(plot3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increase the plot widths\n",
    "plot1.plot_width = plot2.plot_width = plot3.plot_width = 800\n",
    "plot1.plot_height = plot2.plot_height = plot3.plot_height = 500\n",
    "\n",
    "\n",
    "# Create three panels, one for each conference\n",
    "state_panel = Panel(child=plot1, title='Count of restaurants by State')\n",
    "kitchen_panel = Panel(child=plot2, title='Count of restaurants by Kitchen')\n",
    "types_panel = Panel(child=plot3, title='Count of restaurants by Type')\n",
    "\n",
    "# Assign the panels to Tabs\n",
    "tabs = Tabs(tabs=[state_panel, kitchen_panel, types_panel])\n",
    "\n",
    "# Show the tabbed layout\n",
    "show(tabs)\n",
    "\n",
    "html = file_html(tabs, CDN, \"General Overview - BarChart\")\n",
    "# print(html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the dataset considers all the reviews from the different users, number of reviews per state, kitchen and type is considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_state_ = df.groupby(['cat_kitchen']).size().reset_index(name='Counts')\n",
    "group_state_['Type'] = group_state_['cat_kitchen'].astype(str)\n",
    "df_dict_ = group_state_.to_dict('list')\n",
    "\n",
    "group_state__ = df.groupby(['cat_type']).size().reset_index(name='Counts')\n",
    "group_state__['Type'] = group_state__['cat_type'].astype(str)\n",
    "df_dict__ = group_state__.to_dict('list')\n",
    "\n",
    "group_state = df.groupby(['state_name']).size().reset_index(name='Counts')\n",
    "group_state['state'] = group_state['state_name'].astype(str)\n",
    "df_dict = group_state.to_dict('list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Count of reviews by State'\n",
    "xlabel = 'State'\n",
    "range_x = group_state.state.unique().tolist()\n",
    "\n",
    "plot1 = figure(x_range=FactorRange(factors=range_x), y_range=(0,1300000), plot_width=800, plot_height=500,\n",
    "               x_axis_label=xlabel, toolbar_location=None, title=title)\n",
    "plot1.vbar(x='state_name', width=0.7, bottom=0,\n",
    "           top='Counts', source=df_dict, color='lightblue')\n",
    "\n",
    "# hover tool\n",
    "plot1.add_tools(HoverTool(tooltips=[('Count', \"@Counts{1}\")]))\n",
    "\n",
    "# axis ticks\n",
    "plot1.xaxis.major_tick_line_color = None \n",
    "plot1.xaxis.minor_tick_line_color = None \n",
    "plot1.yaxis.major_tick_line_color = None  \n",
    "plot1.yaxis.minor_tick_line_color = None  \n",
    "plot1.title.text_font_size = '13pt'\n",
    "plot1.title.align = 'center'\n",
    "\n",
    "# show(plot1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Count of reviews by Kitchen'\n",
    "range_x = group_state_['cat_kitchen'].unique().tolist()\n",
    "xlabel = 'Kitchen type'\n",
    "\n",
    "plot2 = figure(x_range=FactorRange(factors=range_x), y_range=(0,1700000), plot_width=800, plot_height=500,\n",
    "               x_axis_label=xlabel, toolbar_location=None, title=title)\n",
    "plot2.vbar(x='Type', width=0.7, bottom=0,\n",
    "           top='Counts', source=df_dict_, color='lightblue')\n",
    "\n",
    "# hover tool\n",
    "plot2.add_tools(HoverTool(tooltips=[('Count', \"@Counts\")]))\n",
    "\n",
    "# axis ticks\n",
    "plot2.xaxis.major_tick_line_color = None \n",
    "plot2.xaxis.minor_tick_line_color = None \n",
    "plot2.yaxis.major_tick_line_color = None  \n",
    "plot2.yaxis.minor_tick_line_color = None  \n",
    "plot2.xaxis.major_label_orientation = \"vertical\"\n",
    "plot2.title.text_font_size = '13pt'\n",
    "plot2.title.align = 'center'\n",
    "\n",
    "# show(plot2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Count of reviews by Type'\n",
    "range_x = group_state__['cat_type'].unique().tolist()\n",
    "xlabel = 'Type'\n",
    "\n",
    "plot3 = figure(x_range=FactorRange(factors=range_x), y_range=(0,1100000),plot_width=600, plot_height=500,\n",
    "               x_axis_label=xlabel, toolbar_location=None, title=title)\n",
    "plot3.vbar(x='Type', width=0.7, bottom=0,\n",
    "           top='Counts', source=df_dict__, color='lightblue')\n",
    "\n",
    "# hover tool\n",
    "plot3.add_tools(HoverTool(tooltips=[('Count', \"@Counts\")]))\n",
    "\n",
    "# axis ticks\n",
    "plot3.xaxis.major_tick_line_color = None \n",
    "plot3.xaxis.minor_tick_line_color = None \n",
    "plot3.yaxis.major_tick_line_color = None  \n",
    "plot3.yaxis.minor_tick_line_color = None  \n",
    "plot3.xaxis.major_label_orientation = \"vertical\"\n",
    "plot3.title.text_font_size = '13pt'\n",
    "plot3.title.align = 'center'\n",
    "\n",
    "# show(plot3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increase the plot widths\n",
    "plot1.plot_width = plot2.plot_width = plot3.plot_width = 800\n",
    "plot1.plot_height = plot2.plot_height = plot3.plot_height = 500\n",
    "\n",
    "\n",
    "# Create three panels, one for each conference\n",
    "state_panel = Panel(child=plot1, title='Count of reviews by State')\n",
    "kitchen_panel = Panel(child=plot2, title='Count of reviews by Kitchen')\n",
    "types_panel = Panel(child=plot3, title='Count of reviews by Type')\n",
    "\n",
    "# Assign the panels to Tabs\n",
    "tabs = Tabs(tabs=[state_panel, kitchen_panel, types_panel])\n",
    "\n",
    "# Show the tabbed layout\n",
    "show(tabs)\n",
    "\n",
    "html = file_html(tabs, CDN, \"Overview Reviews\")\n",
    "# print(html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Score Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stars_df = restaurants.groupby(['state_name','stars']).size().reset_index(name='counts')\n",
    "stars_df = stars_df.pivot_table(values = 'counts', index='state_name', columns='stars').reset_index()\n",
    "stars_df = stars_df.rename(columns={1.0:'1', 1.5:'1.5',2.0:'2',2.5:'2.5',\n",
    "                                    3.0:'3',3.5:'3.5',4.0:'4',4.5:'4.5',5.0:'5'}) \n",
    "stars_df = stars_df.fillna(0)\n",
    "source = ColumnDataSource(stars_df)\n",
    "\n",
    "title = 'Count of stars by State'\n",
    "range_x = restaurants['state_name'].sort_values().unique().tolist()\n",
    "xlabel = 'States'\n",
    "stack = ['1', '1.5', '2', '2.5', '3', '3.5', '4', '4.5', '5']\n",
    "colors = ['#30678d','#08306b', '#08519c', '#2171b5', '#4292c6', '#6baed6', '#9ecae1', '#c6dbef', '#deebf7']\n",
    "\n",
    "state = figure(x_range=FactorRange(factors=range_x), y_range=(0,2400),plot_width=800, plot_height=550,\n",
    "           x_axis_label=xlabel, toolbar_location=None, tools=\"\",\n",
    "           title=title)\n",
    "\n",
    "renderers = state.vbar_stack(stack, x='state_name', width=0.9, color=colors, source=source,\n",
    "             legend_label=stack)\n",
    "\n",
    "\n",
    "for r in renderers:\n",
    "    year = r.name\n",
    "    hover = HoverTool(tooltips=[\n",
    "        (\"Total # of stars that have %s\" % year, \"@%s\" % year),\n",
    "        (\"index\", \"$index\")\n",
    "    ], renderers=[r])\n",
    "    state.add_tools(hover)\n",
    "\n",
    "# axis ticks\n",
    "state.yaxis.ticker = [0, 500, 1000, 1500, 2000, 2500]\n",
    "state.xaxis.major_tick_line_color = None \n",
    "state.xaxis.minor_tick_line_color = None \n",
    "state.yaxis.major_tick_line_color = None  \n",
    "state.yaxis.minor_tick_line_color = None  \n",
    "state.legend.location = \"top_center\"\n",
    "state.legend.label_text_font_size = \"7pt\"\n",
    "state.legend.orientation = \"horizontal\"\n",
    "state.title.text_font_size = '13pt'\n",
    "state.title.align = 'center'\n",
    "\n",
    "# show(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stars_df = restaurants.groupby(['cat_kitchen','stars']).size().reset_index(name='counts')\n",
    "stars_df = stars_df.pivot_table(values = 'counts', index='cat_kitchen', columns='stars').reset_index()\n",
    "stars_df = stars_df.rename(columns={1.0:'1', 1.5:'1.5',2.0:'2',2.5:'2.5',\n",
    "                                    3.0:'3',3.5:'3.5',4.0:'4',4.5:'4.5',5.0:'5'}) \n",
    "\n",
    "stars_df = stars_df.fillna(0)\n",
    "source = ColumnDataSource(stars_df)\n",
    "\n",
    "title = 'Count of stars by Kitchen'\n",
    "range_x = restaurants['cat_kitchen'].sort_values().unique().tolist()\n",
    "xlabel = 'Kitchen Types'\n",
    "ylabel = '# of stars'\n",
    "stack = ['1', '1.5', '2', '2.5', '3', '3.5', '4', '4.5', '5']\n",
    "colors = ['#30678D','#08306b', '#08519c', '#2171b5', '#4292c6', '#6baed6', '#9ecae1', '#c6dbef', '#deebf7']\n",
    "\n",
    "kitchen = figure(x_range=FactorRange(factors=range_x), y_range=(0,2400), plot_width=800, plot_height=500,\n",
    "           x_axis_label=xlabel,toolbar_location=None, tools=\"\",\n",
    "           title=title)\n",
    "\n",
    "renderers = kitchen.vbar_stack(stack, x='cat_kitchen', width=0.9, color=colors, source=source,\n",
    "             legend_label=stack)\n",
    "\n",
    "for r in renderers:\n",
    "    year = r.name\n",
    "    hover = HoverTool(tooltips=[\n",
    "        (\"Total # of stars that have %s\" % year, \"@%s\" % year),\n",
    "        (\"index\", \"$index\")\n",
    "    ], renderers=[r])\n",
    "    kitchen.add_tools(hover)\n",
    "\n",
    "# axis ticks\n",
    "kitchen.xaxis.major_tick_line_color = None \n",
    "kitchen.xaxis.minor_tick_line_color = None \n",
    "kitchen.yaxis.major_tick_line_color = None  \n",
    "kitchen.yaxis.minor_tick_line_color = None  \n",
    "kitchen.legend.location = \"top_center\"\n",
    "kitchen.legend.label_text_font_size = \"7pt\"\n",
    "kitchen.legend.orientation = \"horizontal\"\n",
    "kitchen.xaxis.major_label_orientation = \"vertical\"\n",
    "kitchen.title.text_font_size = '13pt'\n",
    "kitchen.title.align = 'center'\n",
    "\n",
    "# show(kitchen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stars_df = restaurants.groupby(['cat_type','stars']).size().reset_index(name='counts')\n",
    "stars_df = stars_df.pivot_table(values = 'counts', index='cat_type', columns='stars').reset_index()\n",
    "stars_df = stars_df.rename(columns={1.0:'1', 1.5:'1.5',2.0:'2',2.5:'2.5',\n",
    "                                    3.0:'3',3.5:'3.5',4.0:'4',4.5:'4.5',5.0:'5'}) \n",
    "\n",
    "stars_df = stars_df.fillna(0)\n",
    "source = ColumnDataSource(stars_df)\n",
    "\n",
    "title = 'Count of stars by Type'\n",
    "range_x = restaurants['cat_type'].sort_values().unique().tolist()\n",
    "xlabel = 'Type'\n",
    "ylabel = '# of stars'\n",
    "stack = ['1', '1.5', '2', '2.5', '3', '3.5', '4', '4.5', '5']\n",
    "stack = ['1', '1.5', '2', '2.5', '3', '3.5', '4', '4.5', '5']\n",
    "colors = ['#30678D','#08306b', '#08519c', '#2171b5', '#4292c6', '#6baed6', '#9ecae1', '#c6dbef', '#deebf7']\n",
    "\n",
    "types = figure(x_range=FactorRange(factors=range_x),y_range=(0,2000), plot_width=800, plot_height=500,\n",
    "           x_axis_label=xlabel ,toolbar_location=None, tools=\"\",\n",
    "           title=title)\n",
    "\n",
    "renderers = types.vbar_stack(stack, x='cat_type', width=0.9, color=colors, source=source,\n",
    "             legend_label=stack)\n",
    "\n",
    "for r in renderers:\n",
    "    year = r.name\n",
    "    hover = HoverTool(tooltips=[\n",
    "        (\"Total # of stars that have %s\" % year, \"@%s\" % year),\n",
    "        (\"index\", \"$index\")\n",
    "    ], renderers=[r])\n",
    "    types.add_tools(hover)\n",
    "\n",
    "# axis ticks\n",
    "types.xaxis.major_tick_line_color = None \n",
    "types.xaxis.minor_tick_line_color = None \n",
    "types.yaxis.major_tick_line_color = None  \n",
    "types.yaxis.minor_tick_line_color = None  \n",
    "types.legend.location = \"top_center\"\n",
    "types.legend.label_text_font_size = \"7pt\"\n",
    "types.legend.orientation = \"horizontal\"\n",
    "types.xaxis.major_label_orientation = \"vertical\"\n",
    "types.title.text_font_size = '13pt'\n",
    "types.title.align = 'center'\n",
    "\n",
    "# show(types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increase the plot widths\n",
    "state.plot_width = kitchen.plot_width = types.plot_width = 800\n",
    "state.plot_height = kitchen.plot_height = types.plot_height = 600\n",
    "\n",
    "# Create three panels, one for each conference\n",
    "state_panel = Panel(child=state, title='Count stars by State')\n",
    "kitchen_panel = Panel(child=kitchen, title='Count stars by Kitchen')\n",
    "types_panel = Panel(child=types, title='Count stars by Type')\n",
    "\n",
    "# Assign the panels to Tabs\n",
    "tabs = Tabs(tabs=[state_panel, kitchen_panel, types_panel])\n",
    "\n",
    "# Show the tabbed layout\n",
    "show(tabs)\n",
    "\n",
    "html = file_html(tabs, CDN, \"Score Overview\")\n",
    "# print(html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Time-based Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Genre\n",
    "\n",
    "### 4.1. Which genre of data story did you use?\n",
    "\n",
    "In the paper from Edward Segel and Jeffrey Heer several genres are described, where multiple of these genres are used to create the content for this website.\n",
    "\n",
    "* The annotated chart is used on the site 'Exploratory Data Analysis' and 'Reviews', since a hover tool with selected and important information is presented for the user. Furthermore, the last map on 'Exploratory Data Analysis' is presenting the timeline in reviews for a given year, where the user can see the number of reviews, stars and of course name of the restaurant.\n",
    "* The annotated chart and animation are also used on the page 'Find your favorite restaurant'. On this page, an interactive figure is presented, where the user can filter data to his/her own preference. The hover tool explained above is still active. Further, if the user is in doubt about how to use the plot, a gif is running above the plot.  \n",
    "\n",
    "### 4.2. Which tools did you use from each of the 3 categories of Visual Narrative?\n",
    "\n",
    "Figure 7 from Edward Segel and Jeffrey Heer's paper presented the three different categories under *Visual Narrative*, where the tools used will be explained here.\n",
    "\n",
    "* Visual Structuring: For visual structuring, a consistent visual platform is used. This gives a good flow through the presentation of our dataset and our findings since the same color palette is used for the graphs and theme for the website. \n",
    "* Highlighting: Here three highlighting methods are used. On the page 'Exploratory Data Analysis',  close-ups, zooming and feature distinction are used. The close-ups are used on the map of where the restaurants are placed in North America and the user is able to zoom. On the other plots, feature distinction is used by the different colors. This is done, so the user can see a difference between for example stars by state. Highlighting is also used for the tab 'Find your favorite restaurant', since the user is first presented with an overview of all the restaurants, again the user can zoom in/out and filter the data by his/her own preferences.\n",
    "* Transition Guidance: Here a simple website setup is used, hence familiar objects are used. This also (hopefully) makes it easier for the user to use the website that is created. \n",
    "\n",
    "### 4.3. Which tools did you use from each of the 3 categories of Narrative Structure?\n",
    "\n",
    "Again, figure 7 from Edward Segel and Jeffrey Heer's paper is used. The narrative structure will be explained throughout this part. \n",
    "\n",
    "* Ordering: As explained above, the website is made with a different post on the front page, where the user can always go back to the front page using the *home* button in the upper right corner. Hence the user can access the tabs he/she wants to. The page 'Exploratory Data Analysis' is driven by the authors of this project, since it is what they found interesting when doing the exploratory part. \n",
    "* Interactivity: On all plots, a hover highlighting is configured, which gives the user easy access to a lot of information by just using the mousepad. Further, an interactive plot is done where the user can filter on the data input to the plot.\n",
    "* Messaging: For this part, multiple messaging is used. When entering the website an introductory text is presented. Further, on all posts, there are headers for all the different sections within each page and captions for all figures. This makes it easy for the user to understand when the topic is changing and to get a brief understanding of what the figures are illustrating. Lastly, annotations for each figure are also present on the website, which is more in detail and for users that want a more in-depth understanding of the dataset. \n",
    "\n",
    "\n",
    "## 5. Visualizations\n",
    "\n",
    "*Explain the visualizations you've chosen.*\n",
    "\n",
    "*Why are they right for the story you want to tell?*\n",
    "\n",
    "The constructed website has three pages with plots. The first page 'Exploratory Data Analysis' has bar charts, line plots and map overview. The second page 'Reviews' is presenting the machine learning model that has been used to detect fake reviews and further presents **HVILKE PLOTS**. Lastly, the last page 'Find your favorite restaurant' is an interactive plot, where a table of all relevant restaurants are seen and a map where the restaurants are placed.\n",
    "\n",
    "These visualizations are good because they give the user easy access to a lot of information, with needing a deeper knowledge. Further, they also give the user access to interact with the last figure. \n",
    "\n",
    "**Er der noget andet mere fornuftigt vi kan skrive?**\n",
    "\n",
    "\n",
    "### 5.1. Anomaly Detection\n",
    "\n",
    "It has been estimated by a Harvard Business School report that 20% of reviews on Yelp are fake. In anomaly detection, the 20% review with the highest risk of being fake reviews is found, by using Isolation Forest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset='text')\n",
    "print(df.columns) #checking our columns\n",
    "print('shape of dataset', df.shape)\n",
    "\n",
    "N = df.shape[0]\n",
    "MaxUsed = 100\n",
    "\n",
    "df = df.iloc[0:N]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creation of features\n",
    "\n",
    "Length of review and number of sentences in the reviews are used as some of the features of the Isolation Forest Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Length of review\n",
    "df['reviewlength'] = df['text'].str.len()\n",
    "\n",
    "#number of sentences\n",
    "df['sentences'] = df[\"text\"].str.count('\\.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text Processing\n",
    "\n",
    "The reviews are processed in the following way:\n",
    "* Stop words are removed\n",
    "* The text is tokenized\n",
    "* The text is stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove stop words\n",
    "df['filtered_text'] = df.text.apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text\n",
    "df['tokenized_text'] = [simple_preprocess(line, deacc=True) for line in df['filtered_text']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stem the text\n",
    "porter_stemmer = PorterStemmer()\n",
    "df['stemmed_tokens'] = [[porter_stemmer.stem(word) for word in tokens] for tokens in df['tokenized_text']]\n",
    "\n",
    "df['stemmed_text'] = df['stemmed_tokens'].apply(' '.join)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the features of the model are if a given word is in the review. The 100 most used words without stop words are found. Most reviews have 5 stars, so to make sure that it doesn't only check for positive words, the 100 most used words are found in a balanced dataset, where there is an equal number of reviews with 1, 2, 3, 4 and 5 stars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count of stars given\n",
    "min_review = min(df['review_stars'].value_counts())\n",
    "\n",
    "#dataframes for each star\n",
    "df1 = df.loc[(df['review_stars'] == 1)]\n",
    "df2 = df.loc[(df['review_stars'] == 2)]\n",
    "df3 = df.loc[(df['review_stars'] == 3)]\n",
    "df4 = df.loc[(df['review_stars'] == 4)]\n",
    "df5 = df.loc[(df['review_stars'] == 5)]\n",
    "\n",
    "#sample dataframe for each star\n",
    "df1 = df1.sample(n=min_review,axis='rows')\n",
    "df2 = df2.sample(n=min_review,axis='rows')\n",
    "df3 = df3.sample(n=min_review,axis='rows')\n",
    "df4 = df4.sample(n=min_review,axis='rows')\n",
    "df5 = df5.sample(n=min_review,axis='rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#balanced reviews\n",
    "df_word = pd.concat([df1, df2, df3, df4, df5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the 100 most used words from the balanced review set(without stop words)\n",
    "Word = []\n",
    "WordCounter = Counter(\" \".join(df_word[\"stemmed_text\"]).split()).most_common(MaxUsed)\n",
    "for j in range(len(WordCounter)):\n",
    "    Word.insert(j,WordCounter[j][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding\n",
    "\n",
    "The reviews are encoded using one-hot-encoding, so for each review, it is checked if they contain each of the 100 most used words from the balanced dataset. \n",
    "\n",
    "Furthermore, userID and businessID are encoded using label encoding, so these also enter as features in the model.\n",
    "\n",
    "Lastly, the date and time are encoded using label encoding, so the date and time can be a feature in the model. This is done by encoding it as year, month, day in the month, hour, minute and the day of the week. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Words = np.zeros((N,MaxUsed))\n",
    "\n",
    "#one-hot encoding over the 100 most used words\n",
    "for index, row in df.iterrows():\n",
    "    for i in range(np.size(Words, axis=1)):\n",
    "        if Word[i] in df['stemmed_text'].iloc[index]:\n",
    "            Words[index,i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop attributes with text\n",
    "df = df.drop(['text','filtered_text','tokenized_text', 'stemmed_tokens',\n",
    "       'stemmed_text'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataframe for encoding\n",
    "df_words = pd.DataFrame(Words)\n",
    "\n",
    "#Encoding column names are changed\n",
    "Names = list(range(0, MaxUsed))\n",
    "ColNames = [str(n) for n in Names]\n",
    "\n",
    "df_words.columns = ColNames\n",
    "print(df_words)\n",
    "\n",
    "#The encoding is added to the dataset\n",
    "df = df.join(df_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label encoding for userID and businessID\n",
    "df['user_id'] = df['user_id'].astype('category')\n",
    "df['business_id'] = df['business_id'].astype('category')\n",
    "\n",
    "df['UserCat'] = df['user_id'].cat.codes\n",
    "df['BusinessCat'] = df['business_id'].cat.codes\n",
    "\n",
    "#encode date\n",
    "df['date']= pd.to_datetime(df['date'])\n",
    "\n",
    "df['year'] = df['date'].dt.year\n",
    "df['month'] = df['date'].dt.month\n",
    "df['day'] = df['date'].dt.day\n",
    "df['hour'] = df['date'].dt.hour\n",
    "df['minute'] = df['date'].dt.minute\n",
    "df['DayOfWeek'] = df['date'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Anomaly detection - Isolation Forest\n",
    "\n",
    "As already mentioned, anomaly detection is performed using an Isolation Forest. The features used in the model is stars the restaurant has, number of reviews received, the star given from the particular review, length of review, number of sentences in the review, userID, businessID, year, month, day in the month, hour, minute, day of the week and the features regarding which of the 100 most used words, the review contains. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features for Isolation Forest\n",
    "df_feature = df[['stars', 'review_count','review_stars','reviewlength', 'sentences', \n",
    "                 'UserCat','BusinessCat', 'year', 'month', 'day', 'hour', 'minute', \n",
    "                 'DayOfWeek', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', \n",
    "                 '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', \n",
    "                 '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', \n",
    "                 '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', \n",
    "                 '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', \n",
    "                 '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', \n",
    "                 '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', \n",
    "                 '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', \n",
    "                 '95', '96', '97', '98', '99']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IsolationForest(n_estimators=50, max_samples='auto', \n",
    "                        contamination=float(0.2),max_features=1).fit(df_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['scores'] = model.decision_function(df_feature)\n",
    "df['anomaly'] = model.predict(df_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop encodings\n",
    "df = df.drop(['reviewlength', 'sentences', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', \n",
    "              '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', \n",
    "              '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', \n",
    "              '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', \n",
    "              '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', \n",
    "              '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74',\n",
    "              '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87',\n",
    "              '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', \n",
    "              'UserCat', 'BusinessCat', 'year', 'month', 'day', 'hour', 'minute', 'DayOfWeek'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Interactive plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24530, 27)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new = df.drop_duplicates(subset=['name','state','cat_kitchen','cat_type'])\n",
    "df_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.bokehjs_exec.v0+json": "",
      "text/html": [
       "\n",
       "<script id=\"5802\">\n",
       "  var xhr = new XMLHttpRequest()\n",
       "  xhr.responseType = 'blob';\n",
       "  xhr.open('GET', \"http://localhost:58246/autoload.js?bokeh-autoload-element=5802&bokeh-absolute-url=http://localhost:58246&resources=none\", true);\n",
       "  \n",
       "  xhr.onload = function (event) {\n",
       "    var script = document.createElement('script'),\n",
       "    src = URL.createObjectURL(event.target.response);\n",
       "    script.src = src;\n",
       "    document.body.appendChild(script);\n",
       "  };\n",
       "xhr.send();\n",
       "</script>"
      ]
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "server_id": "73a17b43766a4717b5b339091395067c"
      }
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:bokeh.server.views.ws:Refusing websocket connection from Origin 'http://localhost:8890';                       use --allow-websocket-origin=localhost:8890 or set BOKEH_ALLOW_WS_ORIGIN=localhost:8890 to permit this; currently we allow origins {'localhost:8888'}\n",
      "WARNING:tornado.access:403 GET /ws (::1) 1.04ms\n"
     ]
    }
   ],
   "source": [
    "def modify_doc(doc):\n",
    "    \n",
    "    def make_dataset(selectedState, selectedKitchen, selectedType, selectedPrice):\n",
    "        df_ = df_new.copy()\n",
    "        df_empty = pd.DataFrame()\n",
    "        if selectedPrice == 'No Preference':  \n",
    "            if selectedState != 'All':\n",
    "                df_ = df_[df_['state_name'] == selectedState]\n",
    "            if selectedKitchen != 'All':\n",
    "                df_ = df_[df_['cat_kitchen'] == selectedKitchen]\n",
    "            if selectedType != 'All':\n",
    "                df_ = df_[df_['cat_type'] == selectedType]\n",
    "        else:\n",
    "            for i, price in enumerate(selectedPrice):\n",
    "                # Subset to the carrier\n",
    "                subset = df_[df_['PriceRange'] == price]\n",
    "                df_empty = df_empty.append(subset)\n",
    "                \n",
    "            if selectedState != 'All':\n",
    "                df_empty = df_empty[df_empty['state_name'] == selectedState]\n",
    "            if selectedKitchen != 'All':\n",
    "                df_empty = df_empty[df_empty['cat_kitchen'] == selectedKitchen]\n",
    "            if selectedType != 'All':\n",
    "                df_empty = df_empty[df_empty['cat_type'] == selectedType]\n",
    "        \n",
    "        if selectedPrice == 'No Preference':\n",
    "            df_ = df_\n",
    "        else:\n",
    "            df_ = df_empty\n",
    "\n",
    "\n",
    "        # Preparing with long/lat coordinates \n",
    "        df_['coordinates'] = list(zip(df_['latitude'], df_['longitude']))\n",
    "        # Obtain list of mercator coordinates\n",
    "        mercators = [x_coord(x, y) for x, y in df_['coordinates'] ]\n",
    "\n",
    "        # Create mercator column in our df\n",
    "        df_['mercator'] = mercators\n",
    "        # Split that column out into two separate columns - mercator_x and mercator_y\n",
    "        df_[['mercator_x', 'mercator_y']] = df_['mercator'].apply(pd.Series)\n",
    "    \n",
    "        #title for the plot  \n",
    "        div_title = Div(text=\"<b> Restaurant matching Preferences: {} </b>\".format(len(df_['name'].unique())),\n",
    "                   style={'font-size': '150%'})\n",
    "        \n",
    "        # Convert dataframe to column data source\n",
    "        return ColumnDataSource(df_), div_title\n",
    "    \n",
    "    def make_plot(source):\n",
    "    \n",
    "        #table in the plot\n",
    "        columns = [\n",
    "            TableColumn(field=\"name\", title=\"Restaurant Name\", width=100),\n",
    "            TableColumn(field=\"stars\", title=\"Stars\", width=50),\n",
    "            TableColumn(field=\"state_name\", title=\"State\", width=80),\n",
    "            TableColumn(field=\"city\", title=\"City\", width=80),\n",
    "            TableColumn(field=\"cat_kitchen\", title=\"Kitchen\", width=110),\n",
    "            TableColumn(field=\"cat_type\", title=\"Type\", width=100),\n",
    "            TableColumn(field=\"PriceRange\", title=\"Price\", width=60)\n",
    "        ]\n",
    "        table = DataTable(source=source, columns=columns, width=660, height=200, fit_columns=False)\n",
    "\n",
    "        #Map layout of North America\n",
    "        tooltips = [(\"Restaurant\",\"@name\"), (\"Stars\", \"@stars\")]\n",
    "\n",
    "        p = figure(x_axis_type=\"mercator\", y_axis_type=\"mercator\", \n",
    "               x_axis_label = 'Longitude', y_axis_label = 'Latitude', \n",
    "               tooltips = tooltips, plot_width=500, plot_height=500, \n",
    "               toolbar_location='below', tools=\"pan,wheel_zoom,reset\", \n",
    "                active_scroll='auto')\n",
    "\n",
    "        p.circle(x = 'mercator_x', y = 'mercator_y', color = 'lightblue', source=source, \n",
    "             size=10, fill_alpha = 0.7)\n",
    "\n",
    "        chosentile = get_provider(Vendors.CARTODBPOSITRON)\n",
    "        p.add_tile(chosentile)\n",
    "\n",
    "        return table, p\n",
    "    \n",
    "    # Update maps\n",
    "    def update(attr, old, new):\n",
    "        \n",
    "        # Get the list of carriers for the graph\n",
    "        selectedState = select_state.value\n",
    "        selectedKitchen = select_kitchen.value\n",
    "        selectedType = select_type.value\n",
    "        selectedPrice = [select_price.labels[i] for i in select_price.active]\n",
    "        \n",
    "        # Make a new dataset based on the selected filters and the make_dataset function defined earlier\n",
    "        new_src, div_title = make_dataset(selectedState, selectedKitchen, selectedType, selectedPrice)\n",
    "        # Update the source used in the quad glpyhs\n",
    "        src.data.update(new_src.data)\n",
    "        \n",
    "        layout.children[0] = div_title\n",
    "\n",
    "        \n",
    "    #selection the different filters\n",
    "    div_subtitle = Div(text=\"<i> Filter with the data and find your favorite restaurant </i>\")\n",
    "\n",
    "    # User select: State\n",
    "    div_state = Div(text=\"<b> Select State </b>\")\n",
    "    state = ['All']+df_new['state_name'].unique().tolist()\n",
    "    select_state = Select(options=state, value=state[0]) #by default All is chosen\n",
    "    select_state.on_change('value', update)\n",
    "\n",
    "    # User select: Kitchen\n",
    "    div_kitchen = Div(text=\"<b> Select Kitchen </b>\")\n",
    "    kitchen = ['All']+df_new['cat_kitchen'].unique().tolist()\n",
    "    select_kitchen = Select(options=kitchen, value=kitchen[0]) #by default All is chosen\n",
    "    select_kitchen.on_change('value', update)\n",
    "\n",
    "    # User select: Type\n",
    "    div_type = Div(text=\"<b> Select Type </b>\")\n",
    "    types = ['All']+df_new['cat_type'].unique().tolist()\n",
    "    select_type = Select(options=types, value=types[0]) #by default All is chosen\n",
    "    select_type.on_change('value', update)\n",
    "\n",
    "    # User select : Price Range\n",
    "    div_price = Div(text=\"<b> Select Price </b>\")\n",
    "    price_range = ['$','$$','$$$','$$$$','Unknown']\n",
    "    select_price = CheckboxButtonGroup(labels=price_range, active=[2,3])\n",
    "    select_price.on_change('active', update)\n",
    "    \n",
    "    #initial source and plot\n",
    "    initial_select_price = [select_price.labels[i] for i in select_price.active]\n",
    "    \n",
    "    src, div_title = make_dataset(select_state.value,select_kitchen.value, select_type.value, initial_select_price)\n",
    "    table, p = make_plot(src)\n",
    "\n",
    "    # Combine all controls to get in column\n",
    "    col_tab_plot = row(table, p, height=200, width=1200)\n",
    "    col_filters_1 = column(div_state, select_state, div_kitchen, select_kitchen , width=290)\n",
    "    col_filters_2 = column(div_type, select_type, div_price, select_price, width=290)\n",
    "\n",
    "    # Layout\n",
    "    layout = column(div_title, div_subtitle, col_tab_plot, row(col_filters_1,col_filters_2)) \n",
    "    #it is possible to add multiple col_filters in the row(), you just need to specify it above\n",
    "    doc.add_root(layout)\n",
    "\n",
    "# Set up an application\n",
    "app = Application(FunctionHandler(modify_doc))\n",
    "show(app)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Discussion\n",
    "\n",
    "\n",
    "Think critically about your creation\n",
    "\n",
    "What went well?,\n",
    "\n",
    "What is still missing? What could be improved?, Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Contriutions\n",
    "\n",
    "(Dette er blot et bud)\n",
    "\n",
    "* Data preprocessing and cleaning:\n",
    "* Exploratory data analysis - General Overview:\n",
    "* Exploratory data analysis - Score Overview:\n",
    "* Exploratory data analysis - Time-based score:\n",
    "* Data Analysis - Anomaly Detection:\n",
    "* Data Analysis - Interactive Bokeh Plot:\n",
    "* Website + GitHub: \n",
    "* Explainer Notebook:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. References\n",
    "[1] Dataset: https://www.yelp.com/dataset\n",
    "\n",
    "[2] https://arturomoncadatorres.com/creating-a-shareable-bokeh-dashboard-with-binder/\n",
    "\n",
    "[3] https://towardsdatascience.com/data-visualization-with-bokeh-in-python-part-one-getting-started-a11655a467d4\n",
    "\n",
    "[4] https://towardsdatascience.com/data-visualization-with-bokeh-in-python-part-iii-a-complete-dashboard-dc6a86aa6e23\n",
    "\n",
    "[5] https://towardsdatascience.com/data-visualization-with-bokeh-in-python-part-ii-interactions-a4cf994e2512\n",
    "\n",
    "[6] https://towardsdatascience.com/discover-your-next-favorite-restaurant-exploration-and-visualization-on-yelps-dataset-157d9799123c"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
